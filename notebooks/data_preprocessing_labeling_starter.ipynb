{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Channel Title</th>\n",
       "      <th>Channel Username</th>\n",
       "      <th>ID</th>\n",
       "      <th>Message</th>\n",
       "      <th>Date</th>\n",
       "      <th>Media Path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>qnash.com - ቅናሽ ®️</td>\n",
       "      <td>@qnashcom</td>\n",
       "      <td>4408</td>\n",
       "      <td>⚡️Kemei ® Rechargeable Hair Clipper \\nየፀጉር መቁረ...</td>\n",
       "      <td>2025-01-18 13:43:51+00:00</td>\n",
       "      <td>data/raw/photos/@qnashcom_4408.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>qnash.com - ቅናሽ ®️</td>\n",
       "      <td>@qnashcom</td>\n",
       "      <td>4407</td>\n",
       "      <td>⚡️Kemei ® Rechargeable Hair Clipper \\nየፀጉር መቁረ...</td>\n",
       "      <td>2025-01-18 08:52:14+00:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>qnash.com - ቅናሽ ®️</td>\n",
       "      <td>@qnashcom</td>\n",
       "      <td>4405</td>\n",
       "      <td>📣 Hair Steamer Cap\\n🔼 High Quality \\n\\n➡️የፀጉር ...</td>\n",
       "      <td>2025-01-18 07:38:38+00:00</td>\n",
       "      <td>data/raw/photos/@qnashcom_4405.jpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>qnash.com - ቅናሽ ®️</td>\n",
       "      <td>@qnashcom</td>\n",
       "      <td>4404</td>\n",
       "      <td>📣 Hair Steamer Cap\\n🔼 High Quality \\n\\n➡️የፀጉር ...</td>\n",
       "      <td>2025-01-17 16:41:32+00:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>qnash.com - ቅናሽ ®️</td>\n",
       "      <td>@qnashcom</td>\n",
       "      <td>4403</td>\n",
       "      <td>📣 Hair Steamer Cap\\n🔼 High Quality \\n\\n➡️የፀጉር ...</td>\n",
       "      <td>2025-01-17 11:35:59+00:00</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Channel Title Channel Username    ID  \\\n",
       "0  qnash.com - ቅናሽ ®️        @qnashcom  4408   \n",
       "1  qnash.com - ቅናሽ ®️        @qnashcom  4407   \n",
       "2  qnash.com - ቅናሽ ®️        @qnashcom  4405   \n",
       "3  qnash.com - ቅናሽ ®️        @qnashcom  4404   \n",
       "4  qnash.com - ቅናሽ ®️        @qnashcom  4403   \n",
       "\n",
       "                                             Message  \\\n",
       "0  ⚡️Kemei ® Rechargeable Hair Clipper \\nየፀጉር መቁረ...   \n",
       "1  ⚡️Kemei ® Rechargeable Hair Clipper \\nየፀጉር መቁረ...   \n",
       "2  📣 Hair Steamer Cap\\n🔼 High Quality \\n\\n➡️የፀጉር ...   \n",
       "3  📣 Hair Steamer Cap\\n🔼 High Quality \\n\\n➡️የፀጉር ...   \n",
       "4  📣 Hair Steamer Cap\\n🔼 High Quality \\n\\n➡️የፀጉር ...   \n",
       "\n",
       "                        Date                          Media Path  \n",
       "0  2025-01-18 13:43:51+00:00  data/raw/photos/@qnashcom_4408.jpg  \n",
       "1  2025-01-18 08:52:14+00:00                                 NaN  \n",
       "2  2025-01-18 07:38:38+00:00  data/raw/photos/@qnashcom_4405.jpg  \n",
       "3  2025-01-17 16:41:32+00:00                                 NaN  \n",
       "4  2025-01-17 11:35:59+00:00                                 NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the necessary libraries\n",
    "import pandas as pd\n",
    "\n",
    "# Load the raw data (assuming you have a file called 'telegram_data.csv' that contains the scraped data)\n",
    "df = pd.read_csv('../data/raw/telegram_data.csv')\n",
    "\n",
    "# Show the first few rows to understand the data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for NaN values in the 'Message' column and drop them\n",
    "print(\"Checking for NaN values in the 'Message' column:\")\n",
    "nan_count = df['Message'].isnull().sum()\n",
    "print(f\"Number of NaN values in 'Message' column: {nan_count}\")\n",
    "\n",
    "# Drop rows with NaN values in the 'Message' column\n",
    "df = df.dropna(subset=['Message'])\n",
    "\n",
    "# Show the dataset shape after dropping NaN values\n",
    "print(f\"Dataset shape after dropping NaN values in 'Message' column: {df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to remove emojis from the text\n",
    "import re\n",
    "\n",
    "def remove_emojis(text):\n",
    "    emoji_pattern = re.compile(\n",
    "        \"[\" \n",
    "        \"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        \"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        \"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        \"\\U0001F700-\\U0001F77F\"  # alchemical symbols\n",
    "        \"\\U0001F780-\\U0001F7FF\"  # Geometric Shapes Extended\n",
    "        \"\\U0001F800-\\U0001F8FF\"  # Supplemental Arrows-C\n",
    "        \"\\U0001F900-\\U0001F9FF\"  # Supplemental Symbols and Pictographs\n",
    "        \"\\U0001FA00-\\U0001FA6F\"  # Chess Symbols\n",
    "        \"\\U0001FA70-\\U0001FAFF\"  # Symbols and Pictographs Extended-A\n",
    "        \"\\U00002702-\\U000027B0\"  # Dingbats\n",
    "        \"\\U000024C2-\\U0001F251\" \n",
    "        \"]+\", \n",
    "        flags=re.UNICODE\n",
    "    )\n",
    "    return emoji_pattern.sub(r'', text)\n",
    "\n",
    "# Apply the emoji removal function to the 'Message' column\n",
    "df['Message'] = df['Message'].apply(remove_emojis)\n",
    "\n",
    "# Show the updated DataFrame\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will define a function to label the data for NER, focusing on product names, prices, and locations.\n",
    "\n",
    "def label_message_with_entities(message):\n",
    "    \"\"\"\n",
    "    Manually label entities in the message.\n",
    "    - B-PRODUCT: Beginning of product name\n",
    "    - I-PRODUCT: Inside product name\n",
    "    - I-PRICE: Inside price entity (e.g., 1000, ብር, $)\n",
    "    - I-LOC: Inside location entity (e.g., Addis Ababa, Bole)\n",
    "    - O: Other text (non-entity)\n",
    "    \"\"\"\n",
    "    labeled_tokens = []\n",
    "    \n",
    "    # Split the message into tokens (words)\n",
    "    tokens = re.findall(r'\\S+', message)\n",
    "    \n",
    "    # Label product names as B-PRODUCT (for first word) and I-PRODUCT (for subsequent words)\n",
    "    if tokens:\n",
    "        labeled_tokens.append(f\"{tokens[0]} B-PRODUCT\")  # First token as B-PRODUCT\n",
    "        for token in tokens[1:]:\n",
    "            labeled_tokens.append(f\"{token} I-PRODUCT\")  # Remaining tokens as I-PRODUCT\n",
    "    \n",
    "    # Label price tokens (e.g., 1000, ብር) as I-PRICE\n",
    "    for idx, token in enumerate(labeled_tokens):\n",
    "        if re.match(r'^\\d{10,}$', token.split()[0]) or re.match(r'^\\d+(\\.\\d{1,2})?$', token.split()[0]):\n",
    "            labeled_tokens[idx] = f\"{token.split()[0]} I-PRICE\"\n",
    "        elif 'ብር' in token or 'ETB' in token or '$' in token:\n",
    "            labeled_tokens[idx] = f\"{token.split()[0]} I-PRICE\"\n",
    "    \n",
    "    # Label location tokens (e.g., Addis Ababa, Bole) as I-LOC\n",
    "    for idx, token in enumerate(labeled_tokens):\n",
    "        if 'Addis Ababa' in token or 'ቦሌ' in token:  # Add more locations as needed\n",
    "            labeled_tokens[idx] = f\"{token.split()[0]} I-LOC\"\n",
    "    \n",
    "    # Label the rest as 'O' for other\n",
    "    labeled_tokens = [f\"{token} O\" for token in labeled_tokens]\n",
    "    \n",
    "    return \"\\n\".join(labeled_tokens)\n",
    "\n",
    "# Apply the labeling function to each message\n",
    "df['Labeled_Message'] = df['Message'].apply(label_message_with_entities)\n",
    "\n",
    "# Display the labeled data\n",
    "df[['Message', 'Labeled_Message']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " ## 4. Save Labeled Data\n",
    "\n",
    "# Save the labeled dataset to a file in CoNLL format\n",
    "labeled_data_path = 'data/labeled/labeled_telegram_product_price_location.txt'\n",
    "with open(labeled_data_path, 'w', encoding='utf-8') as f:\n",
    "    for index, row in df.iterrows():\n",
    "        f.write(f\"{row['Labeled_Message']}\\n\\n\")\n",
    "\n",
    "print(f\"Labeled data saved to {labeled_data_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
